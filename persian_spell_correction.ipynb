{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vhwEz8uez_vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ef3179-d422-485e-f33e-c13b3b558aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dd7-hzTbhffR2mqRPok9wbtAbWWfoUqW\n",
            "To: /content/economics.zip\n",
            "100% 147M/147M [00:00<00:00, 286MB/s]\n",
            "Archive:  economics.zip\n",
            "replace economics.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YRH6TL6uPTSweszOOcPUT2tvzVbI_zJS\n",
            "To: /content/politics.zip\n",
            "100% 101M/101M [00:00<00:00, 294MB/s] \n",
            "Archive:  politics.zip\n",
            "replace politics.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L0OoEOy2XJUgIDbnoWh-l8bhK31kOE9I\n",
            "To: /content/sports.zip\n",
            "100% 171M/171M [00:00<00:00, 280MB/s]\n",
            "Archive:  sports.zip\n",
            "replace sports.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LskvRA05fTXcTMgWsvfd302C8nG2Eq_o\n",
            "To: /content/cultural.zip\n",
            "100% 109M/109M [00:00<00:00, 227MB/s] \n",
            "Archive:  cultural.zip\n",
            "replace cultural.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "# download each subject from google drive\n",
        "! gdown --id 1dd7-hzTbhffR2mqRPok9wbtAbWWfoUqW\n",
        "! unzip economics.zip\n",
        "\n",
        "! gdown --id 1YRH6TL6uPTSweszOOcPUT2tvzVbI_zJS\n",
        "! unzip politics.zip\n",
        "\n",
        "! gdown --id 1L0OoEOy2XJUgIDbnoWh-l8bhK31kOE9I\n",
        "! unzip sports.zip\n",
        "\n",
        "! gdown --id 1LskvRA05fTXcTMgWsvfd302C8nG2Eq_o\n",
        "! unzip cultural.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ltBGbhzYz_0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f802d1-0327-4cd1-dddf-7c9a2ef8d413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '2-nlp-language-modeling'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 159 (delta 108), reused 133 (delta 106), pack-reused 23\u001b[K\n",
            "Receiving objects: 100% (159/159), 44.31 MiB | 18.08 MiB/s, done.\n",
            "Resolving deltas: 100% (110/110), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/language-ml/2-nlp-language-modeling.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_hIYUVAEz_3O"
      },
      "outputs": [],
      "source": [
        "!mv 2-nlp-language-modeling/* ./\n",
        "!rm -rf 2-nlp-language-modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m6eKl_Yw0Ici",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605b3685-e845-4155-b638-79e257606d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 12.5 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394489 sha256=fa5154ee3fb477b9de6ee483408d77e172a0cbc41da9592c87c5aa406ff707c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154425 sha256=010aa3e805692fdd4086b63f79e70ccf65d187319dd40846c199957ec8e99529\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 13.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 60.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting strsimpy\n",
            "  Downloading strsimpy-0.2.1-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: strsimpy\n",
            "Successfully installed strsimpy-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm\n",
        "!pip install transformers\n",
        "!pip install strsimpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XzwrG4D-0LOc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import codecs\n",
        "from itertools import product\n",
        "import math\n",
        "import itertools\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from pprint import pprint\n",
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "from strsimpy.weighted_levenshtein import WeightedLevenshtein\n",
        "import torch \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from transformers import AutoConfig, AutoTokenizer, BertForMaskedLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8DLZap6G0QCY"
      },
      "outputs": [],
      "source": [
        "def read_file_and_sample(file, sample_size):\n",
        "  file_lines = []\n",
        "  with open(file) as f:\n",
        "    for line in f:\n",
        "      file_lines.append(line)\n",
        "    sampled_file = random.sample(file_lines, sample_size)\n",
        "  return sampled_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jpIOw24S0TxY"
      },
      "outputs": [],
      "source": [
        "sampled_politics = read_file_and_sample('politics.txt', 300000)\n",
        "sampled_economics = read_file_and_sample('economics.txt',300000)\n",
        "sampled_sports = read_file_and_sample('sports.txt',300000)\n",
        "sampled_cultural = read_file_and_sample('cultural.txt',300000)\n",
        "# combining all samples\n",
        "all_samples = sampled_politics + sampled_economics + sampled_sports + sampled_cultural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SNceVMWB0V-s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "6e563f51cbd44cf8bb50515a6dc7212f",
            "96497e879173411f905a4c87982837f2",
            "f4615396caef4d46878a3be4ee6ef5ca",
            "5bc40f7ab83e42e7a045f86951145806",
            "9e138636469b41d69d80b9de08c8e741",
            "9a59334706964a9388ab9113c28a0d9c",
            "0a5add1bbb814e1a9bf5629af3f832fa",
            "c3368b8c01ab4628b1c8c3e3b29fc22f",
            "6df30f0b6a17485aa865ca8b94167f4a",
            "95668770a13f4cc09d4a64853382a81c",
            "5ed8db8f64104ea4a14f9626e5395c6a"
          ]
        },
        "outputId": "fadbd766-0c9e-4021-da1d-cbc15a82d65e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1200000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e563f51cbd44cf8bb50515a6dc7212f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "normalizer = Normalizer()\n",
        "all_samples_normalized = [normalizer.normalize(x) for x in tqdm.tqdm_notebook(all_samples)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gyZ5LiSA0XvZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "eb797ac073b14ee7bea4cbd5adb8b9e8",
            "39956140faa34a4099233b76c440417d",
            "a41fd0dd78274a0299ec0af8bb1c7d35",
            "8f89cf97503e4b8d941998d1fab2096f",
            "ca03d56066b2436d9dc7b64ede7c6562",
            "f3a9630b5d624fa384118455d492fad3",
            "0adb52a86a454461bad8946bed4b0783",
            "94ca4c33582a410aa3322dc400d44a8f",
            "94f59a27f4d54fa092a9f8b737ad4192",
            "1e045e16d9704da3ba11c802cf8ff476",
            "8e6e088f42fd4c4f97a59f620b9da931"
          ]
        },
        "outputId": "7bbb17ee-9f33-489d-8475-2e07c0889d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1200000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb797ac073b14ee7bea4cbd5adb8b9e8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "all_sentences = [sent_tokenize(x) for x in tqdm.tqdm_notebook(all_samples_normalized)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = list(itertools.chain(*all_sentences))"
      ],
      "metadata": {
        "id": "VGNSCZ3Gt8u5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UaXjwhSv_eaE"
      },
      "outputs": [],
      "source": [
        "stopwords = [normalizer.normalize(x.strip()) for x in codecs.open('farsi/stopwords.txt','r','utf-8').readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BM74_agg_wct"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(object):\n",
        "    \"\"\"An n-gram language model trained on a given corpus.\n",
        "    \n",
        "    For a given n and given training corpus, constructs an n-gram language\n",
        "    model for the corpus by:\n",
        "    1. preprocessing the corpus (adding SOS/EOS/UNK tokens)\n",
        "    2. calculating (smoothed) probabilities for each n-gram\n",
        "    Also contains methods for calculating the perplexity of the model\n",
        "    against another corpus, and for generating sentences.\n",
        "    Args:\n",
        "        train_data (list of str): list of sentences comprising the training corpus.\n",
        "        n (int): the order of language model to build (i.e. 1 for unigram, 2 for bigram, etc.).\n",
        "        laplace (int): lambda multiplier to use for laplace smoothing (default 1 for add-1 smoothing).\n",
        "    \"\"\"\n",
        "\n",
        "    SOS = \"<s>\"\n",
        "    EOS = \"</s>\"\n",
        "    UNK = \"<UNK>\"\n",
        "    \n",
        "    def __init__(self, train_data, n, laplace=1):\n",
        "        self.n = n\n",
        "        self.vocab = dict()\n",
        "        self.laplace = laplace\n",
        "        self.tokens = self.preprocess(train_data, n)\n",
        "        self.vocab  = nltk.FreqDist(self.tokens)\n",
        "        self.model  = self._create_model()\n",
        "        self.masks  = list(reversed(list(product((0,1), repeat=n))))\n",
        "\n",
        "    def _smooth(self):\n",
        "        \"\"\"Apply Laplace smoothing to n-gram frequency distribution.\n",
        "        \n",
        "        Here, n_grams refers to the n-grams of the tokens in the training corpus,\n",
        "        while m_grams refers to the first (n-1) tokens of each n-gram.\n",
        "        Returns:\n",
        "            dict: Mapping of each n-gram (tuple of str) to its Laplace-smoothed \n",
        "            probability (float).\n",
        "        \"\"\"\n",
        "        vocab_size = len(self.vocab)\n",
        "\n",
        "        n_grams = nltk.ngrams(self.tokens, self.n)\n",
        "        n_vocab = nltk.FreqDist(n_grams)\n",
        "\n",
        "        m_grams = nltk.ngrams(self.tokens, self.n-1)\n",
        "        m_vocab = nltk.FreqDist(m_grams)\n",
        "\n",
        "        def smoothed_count(n_gram, n_count):\n",
        "            m_gram = n_gram[:-1]\n",
        "            m_count = m_vocab[m_gram]\n",
        "            return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
        "\n",
        "        return { n_gram: smoothed_count(n_gram, count) for n_gram, count in n_vocab.items() }\n",
        "\n",
        "    def _create_model(self):\n",
        "        \"\"\"Create a probability distribution for the vocabulary of the training corpus.\n",
        "        \n",
        "        If building a unigram model, the probabilities are simple relative frequencies\n",
        "        of each token with the entire corpus.\n",
        "        Otherwise, the probabilities are Laplace-smoothed relative frequencies.\n",
        "        Returns:\n",
        "            A dict mapping each n-gram (tuple of str) to its probability (float).\n",
        "        \"\"\"\n",
        "        if self.n == 1:\n",
        "            num_tokens = len(self.tokens)\n",
        "            return { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
        "        else:\n",
        "            return self._smooth()\n",
        "\n",
        "    def _convert_oov(self, ngram):\n",
        "        \"\"\"Convert, if necessary, a given n-gram to one which is known by the model.\n",
        "        Starting with the unmodified ngram, check each possible permutation of the n-gram\n",
        "        with each index of the n-gram containing either the original token or <UNK>. Stop\n",
        "        when the model contains an entry for that permutation.\n",
        "        This is achieved by creating a 'bitmask' for the n-gram tuple, and swapping out\n",
        "        each flagged token for <UNK>. Thus, in the worst case, this function checks 2^n\n",
        "        possible n-grams before returning.\n",
        "        Returns:\n",
        "            The n-gram with <UNK> tokens in certain positions such that the model\n",
        "            contains an entry for it.\n",
        "        \"\"\"\n",
        "        mask = lambda ngram, bitmask: tuple((token if flag == 1 else \"<UNK>\" for token,flag in zip(ngram, bitmask)))\n",
        "\n",
        "        ngram = (ngram,) if type(ngram) is str else ngram\n",
        "        for possible_known in [mask(ngram, bitmask) for bitmask in self.masks]:\n",
        "            if possible_known in self.model:\n",
        "                return possible_known\n",
        "\n",
        "    def sent_probability(self, test_data):\n",
        "        test_tokens = test_data.split()\n",
        "        test_tokens = self.replace_singletons(test_tokens)\n",
        "        known_ngram = self._convert_oov(tuple(test_tokens))\n",
        "        prob = self.model[known_ngram]\n",
        "        return prob\n",
        "\n",
        "    def perplexity(self, test_data):\n",
        "        \"\"\"Calculate the perplexity of the model against a given test corpus.\n",
        "        \n",
        "        Args:\n",
        "            test_data (list of str): sentences comprising the training corpus.\n",
        "        Returns:\n",
        "            The perplexity of the model as a float.\n",
        "        \n",
        "        \"\"\"\n",
        "        test_tokens = self.preprocess(test_data, self.n)\n",
        "        test_ngrams = nltk.ngrams(test_tokens, self.n)\n",
        "        N = len(test_tokens)\n",
        "\n",
        "        known_ngrams  = [self._convert_oov(ngram) for ngram in test_ngrams]\n",
        "        probabilities = [self.model[ngram] for ngram in known_ngrams]\n",
        "        \n",
        "        for x,y in zip(known_ngrams, probabilities):\n",
        "            print(x,y)\n",
        "        \n",
        "        return math.exp((-1/N) * sum(map(math.log, probabilities)))\n",
        "\n",
        "    def _best_candidate(self, prev, without=[]):\n",
        "        \n",
        "        blacklist  = [LanguageModel.UNK] + without\n",
        "\n",
        "        if len(prev) < self.n:\n",
        "            prev = [LanguageModel.SOS]*(self.n-1)\n",
        "\n",
        "        candidates = list(((ngram[-1],prob) for ngram,prob in self.model.items() if ngram[:-1]==tuple(prev)))\n",
        "\n",
        "        probs = [y for x,y in candidates]\n",
        "        probs = probs/np.sum(probs)\n",
        "        words = [x for x,y in candidates]\n",
        "\n",
        "        idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
        "        \n",
        "        while words[idx] in blacklist:\n",
        "            idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
        "        \n",
        "        return (words[idx], probs[idx])\n",
        "         \n",
        "    def generate_sentence(self, min_len=12, max_len=24):\n",
        "        sent, prob = ([LanguageModel.SOS] * (max(1, self.n-1)), 1)\n",
        "        while sent[-1] != LanguageModel.EOS:\n",
        "            prev = () if self.n == 1 else tuple(sent[-(self.n-1):])\n",
        "            blacklist = sent + ([LanguageModel.EOS,LanguageModel.SOS] if len(sent) < min_len else [])\n",
        "            next_token, next_prob = self._best_candidate(prev, without=blacklist)\n",
        "            sent.append(next_token)\n",
        "            prob *= next_prob\n",
        "\n",
        "            if len(sent) >= max_len:\n",
        "                sent.append(LanguageModel.EOS)\n",
        "\n",
        "        return (' '.join(sent[(self.n-1):-1]), -1/math.log(prob))\n",
        "    \n",
        "    \n",
        "\n",
        "    def add_sentence_tokens(self, sentences, n):\n",
        "        \"\"\"Wrap each sentence in SOS and EOS tokens.\n",
        "        For n >= 2, n-1 SOS tokens are added, otherwise only one is added.\n",
        "        Args:\n",
        "            sentences (list of str): the sentences to wrap.\n",
        "            n (int): order of the n-gram model which will use these sentences.\n",
        "        Returns:\n",
        "            List of sentences with SOS and EOS tokens wrapped around them.\n",
        "        \"\"\"\n",
        "        sos = ' '.join([LanguageModel.SOS] * (n-1)) if n > 1 else LanguageModel.SOS\n",
        "        return ['{} {} {}'.format(sos, s, LanguageModel.EOS) for s in sentences]\n",
        "\n",
        "    def replace_singletons(self, tokens):\n",
        "        \"\"\"Replace tokens which appear only once in the corpus with <UNK>.\n",
        "\n",
        "        Args:\n",
        "            tokens (list of str): the tokens comprising the corpus.\n",
        "        Returns:\n",
        "            The same list of tokens with each singleton replaced by <UNK>.\n",
        "\n",
        "        \"\"\"\n",
        "        if len(self.vocab) == 0:\n",
        "            self.vocab = nltk.FreqDist(tokens)\n",
        "        return [token if self.vocab[token] > 1 else LanguageModel.UNK for token in tokens]\n",
        "\n",
        "    def preprocess(self, sentences, n):\n",
        "        \"\"\"Add SOS/EOS/UNK tokens to given sentences and tokenize.\n",
        "        Args:\n",
        "            sentences (list of str): the sentences to preprocess.\n",
        "            n (int): order of the n-gram model which will use these sentences.\n",
        "        Returns:\n",
        "            The preprocessed sentences, tokenized by words.\n",
        "        \"\"\"\n",
        "        sentences = self.add_sentence_tokens(sentences, n)\n",
        "        tokens = ' '.join(sentences).split()\n",
        "        tokens = self.replace_singletons(tokens)\n",
        "        return tokens    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ifke7BgXAKeW"
      },
      "outputs": [],
      "source": [
        "#3_gram module\n",
        "language_model = LanguageModel(sentences, 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model v3.0\n",
        "model_name_or_path = \"HooshvareLab/bert-fa-zwnj-base\"\n",
        "config = AutoConfig.from_pretrained(model_name_or_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "vocabulary = [tokenizer.decode(idx) for idx in range(42000)]\n",
        "for j, voc in enumerate(vocabulary):\n",
        "    if \"##\" in voc:\n",
        "        vocabulary[j] = voc[2:]\n",
        "model = BertForMaskedLM.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "id": "EjZ04pc4h9zM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insertion_cost(char):\n",
        "    return 1.5\n",
        "\n",
        "def deletion_cost(char):\n",
        "    return 1.5\n",
        "\n",
        "def substitution_cost(char_a, char_b):\n",
        "    return 1.0\n",
        "\n",
        "weighted_levenshtein = WeightedLevenshtein(\n",
        "    substitution_cost_fn=substitution_cost,\n",
        "    insertion_cost_fn=insertion_cost,\n",
        "    deletion_cost_fn=deletion_cost)\n",
        "\n"
      ],
      "metadata": {
        "id": "KWv2xdSQAe3C"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 10))"
      ],
      "metadata": {
        "id": "CVrpBFilAkk_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_scores(parsbert_scores, meds, n_gram_scores, alpha=1, beta=5, gamma=1):\n",
        "    return alpha*parsbert_scores - beta*meds + gamma*n_gram_scores"
      ],
      "metadata": {
        "id": "cZkAdGEXT4RC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def farsi_spell_correction(text, token, idx):\n",
        "  inputs = tokenizer(text, return_tensors='pt')\n",
        "  with torch.no_grad():\n",
        "    logits = model(**inputs).logits.squeeze()\n",
        "  mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "  predicted_token_id = logits[mask_token_index]\n",
        "  copy_parsbert_scores = torch.clone(predicted_token_id)\n",
        "  for _ in range(500):\n",
        "      i = copy_parsbert_scores.argmax()\n",
        "      if weighted_levenshtein.distance(tokenizer.decode(i), token) < 2:\n",
        "          return tokenizer.decode(i)\n",
        "      copy_parsbert_scores[0, i] = -np.Inf\n",
        "  del copy_parsbert_scores    \n",
        "  predicted_token_id.resize_(42000, 1)\n",
        "  scaled_parsbert_scores = scaler.fit_transform(predicted_token_id)\n",
        "  meds = np.array([weighted_levenshtein.distance(token, vocab) for vocab in vocabulary])\n",
        "  scaled_meds = scaler.fit_transform(meds.reshape(-1, 1))\n",
        "  text = '<s> ' + text + ' </s>'\n",
        "  text = text.split()\n",
        "  n_gram_scores = [language_model.sent_probability(text[idx-1]+\" \"+vocab+ \" \"+text[idx+1]) for vocab in vocabulary][0]\n",
        "  n_gram_scores = np.array(n_gram_scores)\n",
        "  n_gram_socres = scaler.fit_transform(n_gram_scores.reshape(-1, 1))\n",
        "  combined_scores = combine_scores(scaled_parsbert_scores, scaled_meds, n_gram_scores, 1, 5, 1)\n",
        "  return tokenizer.decode(combined_scores.argmax())"
      ],
      "metadata": {
        "id": "FPURMUBTmb_o"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  sent = input(\"لطفا جمله‌ای بنویسید: \")\n",
        "  time_start = time.time()\n",
        "  sent = sent.split()\n",
        "  for idx in range(len(sent)):\n",
        "    token = sent[idx]\n",
        "    sent[idx] = '[MASK]'\n",
        "    res = farsi_spell_correction(\" \".join(sent), token, idx)\n",
        "    sent[idx] = res\n",
        "  result = \" \".join(sent)\n",
        "  print(\"پس از تصحیح : \", result)\n",
        "  print(f\"It took: {time.time() - time_start:.4f}s\")\n",
        "  print(\"-\"*50)\n",
        "  exit = input(\"(بله)می‌خواهید خارج شوید؟ \")\n",
        "  if exit == 'بله':\n",
        "      break"
      ],
      "metadata": {
        "id": "rCexj4OAA7L3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cff692-e3c8-463b-aef9-a57f1dfc2726"
      },
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "لطفا جمله‌ای بنویسید: ظعفران غضا را بسیار خوشمذه می‌کند\n",
            "پس از تصحیح :  زعفران غذا را بسیار خوشمزه میکند\n",
            "It took: 2.4351s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: شهنامه فردوسی بهترین اسر ایزان است\n",
            "پس از تصحیح :  شاهنامه فردوسی بهترین اثر ایران است\n",
            "It took: 2.2757s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: وقتی آسمان پرستاره را با ائجاب مرور می کنیم یا بر ساهل دریا یا رودخـانه می نشینیم وقت خود را تلف نکرده ایم این ها جزع زندگی است به خصوص اگر با تأمّل و فکر و ابرت همراه باشد\n",
            "پس از تصحیح :  وقتی اسمان پرستاره را بر اعجاب مرور مى کنیم یا در ساحل دریا یا رودخانه می نشینیم وقتی خود را تلف کرده ایم این هم جز زندگی است به خصوص اگر با تامل و تفکر و عبرت همراه باشید\n",
            "It took: 9.6510s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: امروز در اخرین لحضات امتحان حالم بد شد\n",
            "پس از تصحیح :  امروز در اخرین لحظات امتحان حالم بد شد\n",
            "It took: 2.3255s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: همد صصد و نهمین صوره از سوره‌های فرآن است\n",
            "پس از تصحیح :  حمد صد و نهمین سوره از سرودهای قران است\n",
            "It took: 4.5029s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: به گزارش خبرنگار انتذامی خبرگزاری فارس، صرقت از صندوق امانات بانک طجارت شعبه دانشگاه خبری بود که روز گذشته منتشر شد\n",
            "پس از تصحیح :  به گزارش خبرنگار انتظامی خبرگزاری فارس سرقت از صندوق امانات بانک تجارت شعبه دانشگاه خبر بود که روز گذشته منتشر شد\n",
            "It took: 8.2804s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: تأیید منشأ ارز مورد نیاز برای واردات خودرو از سوی بانک مرکضی، مهمترین الذام پیش روی واردکنندگان خودرو خواهد بود\n",
            "پس از تصحیح :  تایید منشا ارز مورد نیاز برای واردات خودرو از سوی بانک مرکزی مهمترین اقدام پیش روی واردکنندگان خودرو خواهد بود\n",
            "It took: 5.7674s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: متأثفانه در ساعت ۵:۳۰ دقیقه بامداد چهارشنبه هجدهم خرداد ماه غظار مصافربری در کیلومتر ۵۰ طبس به یزد از ریل خارج شد\n",
            "پس از تصحیح :  متاسفانه در ساعت ۵۳۰ دقیقه بامداد چهارشنبه هفدهم مرداد ماه قطار مسافربری در کیلومتر ۵ طبس به یزد از ریل خارج شد\n",
            "It took: 6.3568s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: ساخت موشک‌های بالستیک ایران به طور خاس طهدیدی برای (رژیم موقت) اسرائیل و نظامیان ایالات مطحده در خاورمیانه است\n",
            "پس از تصحیح :  ساخت موشکهای بالستیک ایران به طور خاص تهدیدی برای رژیم موقت اسراییل و نظامیان ایالات متحده در خاورمیانه است\n",
            "It took: 2.2364s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ \n",
            "لطفا جمله‌ای بنویسید: دبیر انجمن شرکت های حمل و نقل ریلی: پیش از این حشدار‌های زیادی در رابطه با وقوع صوانح در حوزه حمل و نقل ریلی داده بودیم\n",
            "پس از تصحیح :  دبیر انجمن شرکت های حمل و نقل ریلی پیش از این هشدارهای زیادی در رابطه با وقوع سوانح در حوزه حمل و نقل ریلی داده بودیم\n",
            "It took: 5.6900s\n",
            "--------------------------------------------------\n",
            "(بله)می‌خواهید خارج شوید؟ بله\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ظعفران غضا را بسیار خوشمذه می‌کند\n",
        "شهنامه فردوسی بهترین اسر ایزان است\n",
        "وقتی آسمان پرستاره را با ائجاب مرور می کنیم یا بر ساهل دریا یا رودخـانه می نشینیم وقت خود را تلف نکرده ایم این ها جزع زندگی است به خصوص اگر با تأمّل و فکر و ابرت همراه باشد\n",
        "امروز در اخرین لحضات امتحان حالم بد شد\n",
        "همد صصد و نهمین صوره از سوره‌های فرآن است\n",
        "به گزارش خبرنگار انتذامی خبرگزاری فارس، صرقت از صندوق امانات بانک طجارت شعبه دانشگاه خبری بود که روز گذشته منتشر شد\n",
        "تأیید منشأ ارز مورد نیاز برای واردات خودرو از سوی بانک مرکضی، مهمترین الذام پیش روی واردکنندگان خودرو خواهد بود\n",
        "متأثفانه در ساعت ۵:۳۰ دقیقه بامداد چهارشنبه هجدهم خرداد ماه غظار مصافربری در کیلومتر ۵۰ طبس به یزد از ریل خارج شد\n",
        "ساخت موشک‌های بالستیک ایران به طور خاس طهدیدی برای (رژیم موقت) اسرائیل و نظامیان ایالات مطحده در خاورمیانه است\n",
        "دبیر انجمن شرکت های حمل و نقل ریلی: پیش از این حشدار‌های زیادی در رابطه با وقوع صوانح در حوزه حمل و نقل ریلی داده بودیم\n",
        "'''"
      ],
      "metadata": {
        "id": "HzaNpq6HW6Ob"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dBldrqZlVo1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "hw3_extra_ram.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e563f51cbd44cf8bb50515a6dc7212f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96497e879173411f905a4c87982837f2",
              "IPY_MODEL_f4615396caef4d46878a3be4ee6ef5ca",
              "IPY_MODEL_5bc40f7ab83e42e7a045f86951145806"
            ],
            "layout": "IPY_MODEL_9e138636469b41d69d80b9de08c8e741"
          }
        },
        "96497e879173411f905a4c87982837f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a59334706964a9388ab9113c28a0d9c",
            "placeholder": "​",
            "style": "IPY_MODEL_0a5add1bbb814e1a9bf5629af3f832fa",
            "value": "100%"
          }
        },
        "f4615396caef4d46878a3be4ee6ef5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3368b8c01ab4628b1c8c3e3b29fc22f",
            "max": 1200000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6df30f0b6a17485aa865ca8b94167f4a",
            "value": 1200000
          }
        },
        "5bc40f7ab83e42e7a045f86951145806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95668770a13f4cc09d4a64853382a81c",
            "placeholder": "​",
            "style": "IPY_MODEL_5ed8db8f64104ea4a14f9626e5395c6a",
            "value": " 1200000/1200000 [03:05&lt;00:00, 6997.46it/s]"
          }
        },
        "9e138636469b41d69d80b9de08c8e741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a59334706964a9388ab9113c28a0d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5add1bbb814e1a9bf5629af3f832fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3368b8c01ab4628b1c8c3e3b29fc22f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df30f0b6a17485aa865ca8b94167f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95668770a13f4cc09d4a64853382a81c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed8db8f64104ea4a14f9626e5395c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb797ac073b14ee7bea4cbd5adb8b9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39956140faa34a4099233b76c440417d",
              "IPY_MODEL_a41fd0dd78274a0299ec0af8bb1c7d35",
              "IPY_MODEL_8f89cf97503e4b8d941998d1fab2096f"
            ],
            "layout": "IPY_MODEL_ca03d56066b2436d9dc7b64ede7c6562"
          }
        },
        "39956140faa34a4099233b76c440417d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3a9630b5d624fa384118455d492fad3",
            "placeholder": "​",
            "style": "IPY_MODEL_0adb52a86a454461bad8946bed4b0783",
            "value": "100%"
          }
        },
        "a41fd0dd78274a0299ec0af8bb1c7d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ca4c33582a410aa3322dc400d44a8f",
            "max": 1200000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94f59a27f4d54fa092a9f8b737ad4192",
            "value": 1200000
          }
        },
        "8f89cf97503e4b8d941998d1fab2096f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e045e16d9704da3ba11c802cf8ff476",
            "placeholder": "​",
            "style": "IPY_MODEL_8e6e088f42fd4c4f97a59f620b9da931",
            "value": " 1200000/1200000 [00:23&lt;00:00, 53717.52it/s]"
          }
        },
        "ca03d56066b2436d9dc7b64ede7c6562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a9630b5d624fa384118455d492fad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0adb52a86a454461bad8946bed4b0783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94ca4c33582a410aa3322dc400d44a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f59a27f4d54fa092a9f8b737ad4192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e045e16d9704da3ba11c802cf8ff476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6e088f42fd4c4f97a59f620b9da931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}